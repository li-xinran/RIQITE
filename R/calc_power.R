
library( tidyverse )

#' Generate a function that makes treatment effects.
#'
#' The function retuned is a function that returns a vector of
#' treatment impacts to go with passed vector of Y0 values.  I.e.,
#' final function is of format tx_function( Y0 ).
#'
#' @param distribution A string name of a distribution.  "constant" is
#'   a constant treatment effect. "scale" is a scaling of Y0.  "rexp"
#'   and "rnorm" are those random distributions.
#' @param ATE the average treatment effect.  Ignored by "scale"
#'   option.
#' @param tx_scale Scaling factor to achieve desired standard
#'   deviation of impacts generated by tx_function by (default is 1).
#'   Ignored by "constant" and "scale" options.
#' @param ... Extra parameters to pass to distribution function (e.g.,
#'   sd for rnorm).
#' @return A function of the form tx_function( Y0 ).
#' @export
tx_function_factory <- function( distribution, ATE = 0, tx_scale = 1, ... ) {
  dots = list( ... )
  if ( distribution == "constant" ) {
    return( function( Y0 ) {
      rep( ATE, length(Y0) )
    } )
  } else if ( distribution == "scale" ) {
    return( function( Y0 ) {
      Y0 * (dots$scale - 1)
    } )
  } else if ( distribution == "rexp") {
    return( function( Y0 ) {
      tx_scale * (rexp( length( Y0 ) ) - 1 ) + ATE
    } )
  } else if ( distribution == "rnorm") {
    return( function( Y0 ) {
      tx_scale * (rnorm( length( Y0 ) ) ) + ATE
    } )
  } else {
    stop( "Unrecognized distribution")
  }
}


#' Generate data for power simulation
#'
#'
#' Given a desired sample size and a data generating mechanism,
#' generate a dataset of Y0s and indiviual treatment effects.
#'
#'
#' @param n Sample size to test
#' @param Y0_distribution Either a function to generate a set of Y0
#'   values, or a list of discrete values to sample from (with
#'   replacement).  Function takes single parameter of sample size.
#'   Default is normal.
#' @param tx_function Function that takes Y0 and returns a set of
#'   treatment effects.  Default is tx_constant.
#' @return Tibble (dataframe) with two columns, one of Y0s and one
#'   (tau) of treatment effects.
#' @export
generate_finite_data <- function( n,
                                  Y0_distribution = rnorm,
                                  tx_function = tx_function_factory("constant") ) {
  Y0s = NA
  if ( is.function(Y0_distribution) ) {
    Y0s = Y0_distribution( n )
  } else {
    stopifnot( is.numeric(Y0_distribution) )
    Y0s = sample( Y0_distribution, n, replace=TRUE )
  }
  tau = tx_function( Y0s )

  tibble( Y0 = Y0s, tau = tau )
}


#' Calculate power for a finite-sample dataset.
#'
#' Given a fixed schedule of potential outcomes and a proportion to
#' assign to treatment, calculate (via simulation) the power to detect
#' a given quantile effect.
#'
#' @inheritParams pval_quantile
#'
#' @param alpha Alpha for testing (default of 0.05)
#' @param R Number of permutation replicates
#' @param percentile Which quantile is of interest (default is 1, the
#'   max)
#' @param c Threshold for null (see pval_quantile)
#'
#' @return Small tibble with statistics of the power calculation (true
#'   effect being tested, power to detect, sample size, etc.)
#' @export
calc_power_finite <- function( Y0, tau, p_tx, R = 100,
                               percentile = 1,
                               alpha = 0.05,
                               c = 0,
                               alternative = "greater",
                               method.list = list(name = "Stephenson", s = 10),
                               score = NULL,
                               stat.null = NULL,
                               nperm = 1000) {
  n = length(Y0)
  stopifnot( percentile >= 0 && percentile <= 1 )
  k = round( percentile * n )

  rps = rerun( R, {
    Z = as.numeric( sample(n) <= p_tx * n )

    Yobs = Y0 + ifelse( Z, tau, 0 )
    pval_quantile( Z, Yobs, k = k, c = 0,
                   alternative = alternative,
                   method.list = method.list,
                   score = score,
                   stat.null = stat.null,
                   nperm = nperm,
                   switch = FALSE )
  } )
  rps = unlist(rps)
  true_tau = sort(tau)[k]
  tibble( n = n, k = k, tau_k = true_tau,
          power = mean(rps <= alpha) )
}





#' Explore power across a range of s values
#'
#' Conduct power simulation against specific finite-sample dataset to
#' see how power changes as a function of s.
#'
#' @param s Numeric list of s values to test using the Stephenson rank.
#' @export
explore_stephenson_s_finite <- function( s = c(2,5,10,30),
                                         Y0, tau, p_tx, R = 100,
                                         percentile = 1,
                                         alpha = 0.05,
                                         c = 0,
                                         alternative = "greater",
                                         score = NULL,
                                         stat.null = NULL,
                                         nperm = 1000) {
  n = length(Y0)
  stopifnot( n == length( tau ) )
  stopifnot( p_tx*n >= 1 && p_tx*n <= n-1 )

  rs = map_df( s, function( ss ) {
    calc_power_finite( Y0 = Y0, tau = tau, p_tx = p_tx, R = R,
                       percentile = percentile,
                       alpha = alpha, c = c,
                       method.list = list(name = "Stephenson", s = ss),
                       alternative = alternative,
                       score = score, stat.null = stat.null, nperm = nperm )
  } )

  rs$s = s
  dplyr::select( rs, s, power )
}



if ( FALSE ) {
  Y0 = rnorm( 500 )
  tau = rexp( 500 ) - 1
  explore_stephenson_s_finite( Y0 = Y0, tau = tau, p_tx = 0.5 )

}



# Fit a MLM to see how much different datasets impacts the
# power.
calc_power_ICC <- function( rps, iter_per_set ) {
  require( lme4 )
  rps$gid = 1:nrow(rps)
  rps$k = round( iter_per_set * rps$power )

  if ( sd( rps$k ) == 0 ) {
    tibble( ICC = NA,
            pow_l = NA,
            pow_h = NA )
  } else {

    M1 = glmer( cbind( k, iter_per_set-k ) ~ 1 + (1|gid), data=rps,
                family=binomial )
    #display( M1 )
    V = VarCorr( M1 )$gid[1,1]
    ICC =  V / ( V + pi^2/3 )
    ICC
    rng = boot::inv.logit( fixef(M1)[[1]] + c( -sqrt(V), sqrt(V) ) )

    tibble( ICC = ICC,
            pow_l = rng[[1]],
            pow_h = rng[[2]] )
  }
}



#' Calculate power for the noninferiority null
#'
#' Given a specified DGP for control outcomes and treatment impacts,
#' calculate power to detect effects.  Calculates superpopulation
#' power via simulation, where we simulate series of datasets of size
#' n, randomized into treatment and control, and then test for
#' detection of effects. Function returns proportion of times effects
#' are detected.
#'
#' Each individual dataset is tested iter_per_set times, giving very
#' rough power calculations for individual sets that are then
#' aggregated; this provides the ability to do variance decomposition
#' to see how sensitive power is to individual dataset characteristics
#' (for datasets of the same family as defined by the DGP) vs.
#' randomization imbalance.
#'
#' @inheritParams generate_finite_data
#'
#' @param iter_per_set Number of permutations per finite dataset.
#' @param calc_ICC Calculate how much
#' @export
calc_power <- function( n,
                        Y0_distribution = rnorm,
                        tx_function = tx_function_factory("constant"),
                        p_tx = 0.5,
                        R = 100, iter_per_set = 10,
                        percentile = 1,
                        alpha = 0.05,
                        c = 0,
                        alternative = "greater",
                        method.list = list(name = "Stephenson", s = 10),
                        score = NULL,
                        stat.null = NULL,
                        nperm = 1000,
                        calc_ICC = FALSE ) {


  one_run <- function( Rint ) {
    dat = generate_finite_data( n = n,
                                Y0_distribution,
                                tx_function )
    calc_power_finite( Y0 = dat$Y0, tau = dat$tau, p_tx = p_tx,
                       R = Rint,
                       percentile = percentile, alpha = alpha,
                       c = c,
                       alternative = alternative, method.list = method.list,
                       score = score, stat.null = stat.null, nperm = nperm )
  }

  n_block = round( R / iter_per_set )
  rps = rerun( n_block, one_run( iter_per_set ) )
  rps <- bind_rows( rps )
  aggrps <- rps %>%
    summarize( n = mean(n),
               k = mean(k),
               sd_tau = sd( .data$tau_k ),
               tau_k = mean(tau_k),
               SEpower = sd( .data$power ) / sqrt( n() ),
               power = mean(power) ) %>%
    relocate( tau_k, sd_tau, power, SEpower, .after = k )

  if ( calc_ICC ) {
    aggrps = cbind( aggrps,
                    calc_power_ICC(rps, iter_per_set) )
  }

  aggrps$method = paste0( method.list, collapse = "-" )
  aggrps
}



if ( FALSE ) {
  pow = calc_power( 500,
                    tx_function = tx_function_factory("rexp"),
                    p_tx = 0.5 )
  pow
}




#' Explore power across a range of s values
#'
#' Conduct power simulation against a specific data generating process to
#' see how power changes as a function of s in that scenario.
#'
#' @param s Numeric list of s values to test using the Stephenson rank.
#' @export
explore_stephenson_s <- function( s = c(2,5,10,30),
                                  n,
                                  Y0_distribution = rnorm,
                                  tx_function = tx_function_factory("constant"),
                                  p_tx = 0.5,
                                  R = 100, iter_per_set = 10,
                                  percentile = 1,
                                  alpha = 0.05,
                                  c = 0,
                                  alternative = "greater",
                                  score = NULL,
                                  stat.null = NULL,
                                  nperm = 1000,
                                  parallel = FALSE,
                                  calc_ICC = FALSE ) {


  one_run <- function( Rint ) {
    require( tidyverse )
    dat = generate_finite_data( n = n,
                                Y0_distribution,
                                tx_function )
    explore_stephenson_s_finite( s = s,
                                 Y0 = dat$Y0, tau = dat$tau,
                                 p_tx = p_tx,
                                 R = Rint,
                                 percentile = percentile, alpha = alpha,
                                 c = c,
                                 alternative = alternative,
                                 score = score, stat.null = stat.null,
                                 nperm = nperm )
  }

  n_blocks = round( R / iter_per_set )

  if ( !parallel ) {
    rps = map( rep( iter_per_set, n_blocks ), one_run )
  } else {
    require( future )
    require( parallel )
    require( furrr )
    future::plan(multisession,
                 workers = parallel::detectCores() - 1 )
    rps = future_map( rep( iter_per_set, n_blocks ),
                       one_run,
                       .options = furrr_options(seed = NULL) )
  }
  rps <- bind_rows( rps, .id = "gid" )

  aggrps <- rps %>% group_by( s ) %>%
    summarise( SEpower = sd( power ) / sqrt( n() ),
               power = mean( power ) ) %>%
    relocate( SEpower, .after = power )

  if ( calc_ICC ) {
    rpg = rps %>% group_by( s ) %>% nest()
    mods = rpg$data %>%
      set_names(rpg$s) %>%
      map_df( calc_power_ICC,
              iter_per_set = iter_per_set,
              .id = "s" ) %>%
      mutate( s = as.numeric( s ) )

    aggrps <- left_join( aggrps, mods, by="s" )
  }

  aggrps
}


if ( FALSE ) {
  ess = explore_stephenson_s( s = c( 2, 4, 5, 7, 10, 30 ),
                              n = 500,
                              tx_function = tx_function_factory("rexp"),
                              p_tx = 0.5 )
  ess

  ess2 = explore_stephenson_s( s = c( 2, 4, 5, 7, 10, 30 ),
                               n = 500,
                               tx_function = tx_function_factory("rnorm",
                                                                 ATE = 0.2),
                               p_tx = 0.5 )
  ess2

  ess3 = explore_stephenson_s( s = c( 2, 4, 5, 7, 10, 30 ),
                               n = 500,
                               tx_function = tx_function_factory("constant",
                                                                 ATE = 0.2),
                               p_tx = 0.5 )
  ess3

  ess4 = explore_stephenson_s( s = c( 2, 4, 5, 7, 10, 30 ),
                               n = 500,
                               Y0_distribution = rexp,
                               tx_function = tx_function_factory("constant",
                                                                 ATE = 0),
                               p_tx = 0.5 )
  ess4



}
